{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167297f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from w1_feature_fraud_mk import collectAllFeaturesBaseline\n",
    "\n",
    "\n",
    "df_fraud_aggregated = collectAllFeaturesBaseline() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b716e7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        column  num_missing  pct_missing   \n",
      "0                                    client_id            0     0.000000  \\\n",
      "1                                       target            0     0.000000   \n",
      "2                     f_invoive_date_diff_days         4212     3.108648   \n",
      "3                 f_invoive_date_median_months         4212     3.108648   \n",
      "4                  f_invoive_date_median_years         4212     3.108648   \n",
      "5               f_counter_statue_error_occured            0     0.000000   \n",
      "6                            f_counter_regions            0     0.000000   \n",
      "7                          f_region_fraud_rate            0     0.000000   \n",
      "8        f_region_median_billing_frequence_per            2     0.001476   \n",
      "9   f_region_std_deviation_consumption_level_1            0     0.000000   \n",
      "10  f_region_std_deviation_consumption_level_2            0     0.000000   \n",
      "11  f_region_std_deviation_consumption_level_3            0     0.000000   \n",
      "12  f_region_std_deviation_consumption_level_4            0     0.000000   \n",
      "13                    consommation_level_1_min            0     0.000000   \n",
      "14                    consommation_level_1_max            0     0.000000   \n",
      "15                    consommation_level_1_std         4212     3.108648   \n",
      "16                   consommation_level_1_mean            0     0.000000   \n",
      "17                    consommation_level_2_min            0     0.000000   \n",
      "18                    consommation_level_2_max            0     0.000000   \n",
      "19                    consommation_level_2_std         4212     3.108648   \n",
      "20                   consommation_level_2_mean            0     0.000000   \n",
      "21                    consommation_level_3_min            0     0.000000   \n",
      "22                    consommation_level_3_max            0     0.000000   \n",
      "23                    consommation_level_3_std         4212     3.108648   \n",
      "24                   consommation_level_3_mean            0     0.000000   \n",
      "25                    consommation_level_4_min            0     0.000000   \n",
      "26                    consommation_level_4_max            0     0.000000   \n",
      "27                    consommation_level_4_std         4212     3.108648   \n",
      "28                   consommation_level_4_mean            0     0.000000   \n",
      "29                            f_index_diff_min            0     0.000000   \n",
      "30                            f_index_diff_max            0     0.000000   \n",
      "31                            f_index_diff_std         4212     3.108648   \n",
      "32                           f_index_diff_mean            0     0.000000   \n",
      "33                     f_total_consumption_min            0     0.000000   \n",
      "34                     f_total_consumption_max            0     0.000000   \n",
      "35                     f_total_consumption_std         4212     3.108648   \n",
      "36                    f_total_consumption_mean            0     0.000000   \n",
      "37                                  tarif_type            0     0.000000   \n",
      "\n",
      "    has_missing  \n",
      "0         False  \n",
      "1         False  \n",
      "2          True  \n",
      "3          True  \n",
      "4          True  \n",
      "5         False  \n",
      "6         False  \n",
      "7         False  \n",
      "8          True  \n",
      "9         False  \n",
      "10        False  \n",
      "11        False  \n",
      "12        False  \n",
      "13        False  \n",
      "14        False  \n",
      "15         True  \n",
      "16        False  \n",
      "17        False  \n",
      "18        False  \n",
      "19         True  \n",
      "20        False  \n",
      "21        False  \n",
      "22        False  \n",
      "23         True  \n",
      "24        False  \n",
      "25        False  \n",
      "26        False  \n",
      "27         True  \n",
      "28        False  \n",
      "29        False  \n",
      "30        False  \n",
      "31         True  \n",
      "32        False  \n",
      "33        False  \n",
      "34        False  \n",
      "35         True  \n",
      "36        False  \n",
      "37        False  \n"
     ]
    }
   ],
   "source": [
    "total = len(df_fraud_aggregated)\n",
    "report = (\n",
    "    pd.DataFrame({\n",
    "    'column': df_fraud_aggregated.columns,\n",
    "        'num_missing': df_fraud_aggregated.isna().sum().values\n",
    "    })\n",
    "    .assign(\n",
    "        pct_missing=lambda d: d['num_missing'] / total * 100,\n",
    "        has_missing=lambda d: d['num_missing'] > 0\n",
    "    )\n",
    ")\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aee319cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[25734 12644]\n",
      " [  847  1423]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.67      0.79     38378\n",
      "         1.0       0.10      0.63      0.17      2270\n",
      "\n",
      "    accuracy                           0.67     40648\n",
      "   macro avg       0.53      0.65      0.48     40648\n",
      "weighted avg       0.92      0.67      0.76     40648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_fraud_aggregated.drop(columns=[\"target\", \"client_id\"])\n",
    "X.fillna(0, inplace=True)  \n",
    "y = df_fraud_aggregated[\"target\"]\n",
    "\n",
    "# 2. Train/Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. Feature-Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# 4. Modell-Definition und Training\n",
    "model = LogisticRegression(\n",
    "    class_weight='balanced',  # hier werden die Klassengewichte automatisch angepasst\n",
    "    solver='liblinear',       # geeignet für kleine bis mittelgroße Datensätze\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 5. Evaluation\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
