{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167297f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/muri/education/spiced/WaterMLOps/ds-mlproject-fraud/fraud.py:58: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self._frames[str(p)] = pd.read_csv(p)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           client_id  target  disrict  region  client_catg\n",
      "0     train_Client_0     0.0       60     101           11\n",
      "1     train_Client_1     0.0       69     107           11\n",
      "2    train_Client_10     0.0       62     301           11\n",
      "3   train_Client_100     0.0       69     105           11\n",
      "4  train_Client_1000     0.0       62     303           11\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from fraud import collectAllFeaturesBaseline\n",
    "\n",
    "\n",
    "df_fraud_aggregated = collectAllFeaturesBaseline() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b716e7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        column  num_missing  pct_missing   \n",
      "0                                    client_id            0     0.000000  \\\n",
      "1                                       target            0     0.000000   \n",
      "2                                      disrict            0     0.000000   \n",
      "3                                       region            0     0.000000   \n",
      "4                                  client_catg            0     0.000000   \n",
      "5                     f_invoive_date_diff_days         4212     3.108648   \n",
      "6                 f_invoive_date_median_months         4212     3.108648   \n",
      "7                  f_invoive_date_median_years         4212     3.108648   \n",
      "8               f_counter_statue_error_occured            0     0.000000   \n",
      "9                            f_counter_regions            0     0.000000   \n",
      "10                       f_t_region_fraud_rate            0     0.000000   \n",
      "11       f_region_median_billing_frequence_per            2     0.001476   \n",
      "12  f_region_std_deviation_consumption_level_1            0     0.000000   \n",
      "13  f_region_std_deviation_consumption_level_2            0     0.000000   \n",
      "14  f_region_std_deviation_consumption_level_3            0     0.000000   \n",
      "15  f_region_std_deviation_consumption_level_4            0     0.000000   \n",
      "16                    consommation_level_1_min            0     0.000000   \n",
      "17                    consommation_level_1_max            0     0.000000   \n",
      "18                    consommation_level_1_std         4212     3.108648   \n",
      "19                   consommation_level_1_mean            0     0.000000   \n",
      "20                    consommation_level_2_min            0     0.000000   \n",
      "21                    consommation_level_2_max            0     0.000000   \n",
      "22                    consommation_level_2_std         4212     3.108648   \n",
      "23                   consommation_level_2_mean            0     0.000000   \n",
      "24                    consommation_level_3_min            0     0.000000   \n",
      "25                    consommation_level_3_max            0     0.000000   \n",
      "26                    consommation_level_3_std         4212     3.108648   \n",
      "27                   consommation_level_3_mean            0     0.000000   \n",
      "28                    consommation_level_4_min            0     0.000000   \n",
      "29                    consommation_level_4_max            0     0.000000   \n",
      "30                    consommation_level_4_std         4212     3.108648   \n",
      "31                   consommation_level_4_mean            0     0.000000   \n",
      "32                            f_index_diff_min            0     0.000000   \n",
      "33                            f_index_diff_max            0     0.000000   \n",
      "34                            f_index_diff_std         4212     3.108648   \n",
      "35                           f_index_diff_mean            0     0.000000   \n",
      "36                     f_total_consumption_min            0     0.000000   \n",
      "37                     f_total_consumption_max            0     0.000000   \n",
      "38                     f_total_consumption_std         4212     3.108648   \n",
      "39                    f_total_consumption_mean            0     0.000000   \n",
      "40                                  tarif_type            0     0.000000   \n",
      "41                    f_t_district_target_mean            0     0.000000   \n",
      "\n",
      "    has_missing  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3         False  \n",
      "4         False  \n",
      "5          True  \n",
      "6          True  \n",
      "7          True  \n",
      "8         False  \n",
      "9         False  \n",
      "10        False  \n",
      "11         True  \n",
      "12        False  \n",
      "13        False  \n",
      "14        False  \n",
      "15        False  \n",
      "16        False  \n",
      "17        False  \n",
      "18         True  \n",
      "19        False  \n",
      "20        False  \n",
      "21        False  \n",
      "22         True  \n",
      "23        False  \n",
      "24        False  \n",
      "25        False  \n",
      "26         True  \n",
      "27        False  \n",
      "28        False  \n",
      "29        False  \n",
      "30         True  \n",
      "31        False  \n",
      "32        False  \n",
      "33        False  \n",
      "34         True  \n",
      "35        False  \n",
      "36        False  \n",
      "37        False  \n",
      "38         True  \n",
      "39        False  \n",
      "40        False  \n",
      "41        False  \n"
     ]
    }
   ],
   "source": [
    "total = len(df_fraud_aggregated)\n",
    "report = (\n",
    "    pd.DataFrame({\n",
    "    'column': df_fraud_aggregated.columns,\n",
    "        'num_missing': df_fraud_aggregated.isna().sum().values\n",
    "    })\n",
    "    .assign(\n",
    "        pct_missing=lambda d: d['num_missing'] / total * 100,\n",
    "        has_missing=lambda d: d['num_missing'] > 0\n",
    "    )\n",
    ")\n",
    "print (report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aee319cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[25817 12561]\n",
      " [  863  1407]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.67      0.79     38378\n",
      "         1.0       0.10      0.62      0.17      2270\n",
      "\n",
      "    accuracy                           0.67     40648\n",
      "   macro avg       0.53      0.65      0.48     40648\n",
      "weighted avg       0.92      0.67      0.76     40648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df_fraud_aggregated.drop(columns=[\"client_id\", \"target\"])\n",
    "#X = df_fraud_aggregated.drop(columns=[\"client_id\", \"target\", \"region\", \"disrict\", \"client_catg\"])\n",
    "X.fillna(0, inplace=True)  \n",
    "y = df_fraud_aggregated[\"target\"]\n",
    "\n",
    "# 2. Train/Test-Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.3,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. Feature-Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# 4. Modell-Definition und Training\n",
    "model = LogisticRegression(\n",
    "    class_weight='balanced',  # hier werden die Klassengewichte automatisch angepasst\n",
    "    solver='liblinear',       # geeignet für kleine bis mittelgroße Datensätze\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 5. Evaluation\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
